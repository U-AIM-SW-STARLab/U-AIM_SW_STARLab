# U-AIM_SW_STARLab
üî•  SW Development of **Causal AI** through Video Understanding and Reinforcement Learning, and Its Applications to Real Environments

## Table of Contents
- [ÏµúÏö∞Ïàò ÎÖºÎ¨∏ Ïã§Ï†Å](#ÏµúÏö∞Ïàò-ÎÖºÎ¨∏-Ïã§Ï†Å)
- [Ïö∞Ïàò ÎÖºÎ¨∏ Ïã§Ï†Å](#Ïö∞Ïàò-ÎÖºÎ¨∏-Ïã§Ï†Å)
- [SCIE Ï†ÄÎÑê Ïã§Ï†Å](#SCIE-Ï†ÄÎÑê-Ïã§Ï†Å)
- [Íµ≠Ï†ú ÌïôÏà† ÎåÄÌöå Ïã§Ï†Å](#Íµ≠Ï†ú-ÌïôÏà†-ÎåÄÌöå-Ïã§Ï†Å)
- [Í∏∞ÌÉÄ ÏÜåÌîÑÌä∏Ïõ®Ïñ¥](#Í∏∞ÌÉÄ-ÏÜåÌîÑÌä∏Ïõ®Ïñ¥)
### üì¢ ÏµúÏö∞Ïàò ÎÖºÎ¨∏ Ïã§Ï†Å
[2025]
- [Can Video LLMs Refuse to Answer? Alignment for Answerability in Video Large Language Models](https://arxiv.org/abs/2507.04976) <br/>
Eunseop Yoon, Hee Suk Yoon, Mark A. Hasegawa-Johnson, Chang D. Yoo, Chang D. Yoo.  International Conference on Learning Representations (ICLR) 2025 <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2312.05790-b31b1b.svg)](https://arxiv.org/abs/2507.04976)
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/EsYoon7/UVQA)
[![Star](https://img.shields.io/github/stars/EsYoon7/UVQA.svg?style=social&label=Star)](https://github.com/EsYoon7/UVQA)

- [MDSGen: Fast and Efficient Masked Diffusion Temporal-Aware Transformers for Open-Domain Sound Generation](https://arxiv.org/abs/2410.02130) <br/>
Trung X. Pham, Tri Ton, Chang D. Yoo.  International Conference on Learning Representations (ICLR) 2025 <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2410.02130-b31b1b.svg)](https://arxiv.org/abs/2410.02130)
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/triton99/MDSGen)
[![Star](https://img.shields.io/github/stars/triton99/MDSGen.svg?style=social&label=Star)](https://github.com/triton99/MDSGen)

- [ITA-MDT: Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On](https://arxiv.org/abs/2503.20418) <br/>
Ji Woo Hong, Tri Ton, Trung X. Pham, Gwanhyeong Koo, Sunjae Yoon, Chang D. Yoo.  The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2025 <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2503.20418-b31b1b.svg)](https://arxiv.org/abs/2503.20418)
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/jiwoohong93/ita-mdt_code)
[![Star](https://img.shields.io/github/stars/jiwoohong93/ita-mdt_code.svg?style=social&label=Star)](https://github.com/jiwoohong93/ita-mdt_code)

- [ConfPO: Exploiting Policy Model Confidence for Critical Token Selection in Preference Optimization](https://arxiv.org/abs/2507.04976) <br/>
Hee Suk Yoon, Eunseop Yoon, Mark A. Hasegawa-Johnson, Sungwoong Kim, Chang D. Yoo.  International Conference on Machine Learning (ICML) 2025 <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2507.04976-b31b1b.svg)](https://arxiv.org/abs/2507.04976)
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/hee-suk-yoon/ConfPO)
[![Star](https://img.shields.io/github/stars/hee-suk-yoon/ConfPO.svg?style=social&label=Star)](https://github.com/hee-suk-yoon/ConfPO)

- [FlowDrag: 3D-aware Drag-based Image Editing with Mesh-guided Deformation Vector Flow Fields](https://arxiv.org/abs/2507.08285) <br/>
Gwanhyeong Koo, Sunjae Yoon, Younghwan Lee, Ji Woo Hong, Chang D. Yoo.  International Conference on Machine Learning (ICML) 2025, [Spotlight (top 2.6%)] <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2507.08285-b31b1b.svg)](https://arxiv.org/abs/2507.08285)
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/kookie12/FlowDrag)
[![Star](https://img.shields.io/github/stars/kookie12/FlowDrag.svg?style=social&label=Star)](https://github.com/kookie12/FlowDrag)

- [Enhancing Rating-Based Reinforcement Learning to Effectively Leverage Feedback from Large Vision-Language Models](https://www.arxiv.org/abs/2506.12822) <br/>
Gwanhyeong Koo, Sunjae Yoon, Younghwan Lee, Ji Woo Hong, Chang D. Yoo.  International Conference on Machine Learning (ICML) 2025 <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2506.12822-b31b1b.svg)](https://www.arxiv.org/abs/2506.12822)
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/tunglm2203/erlvlm)
[![Star](https://img.shields.io/github/stars/tunglm2203/erlvlm.svg?style=social&label=Star)](https://github.com/tunglm2203/erlvlm)

- [Occlusion-robust Stylization for Drawing-based 3D Animation](https://arxiv.org/abs/2508.00398) <br/>
Gwanhyeong Koo, Sunjae Yoon, Younghwan Lee, Ji Woo Hong, Chang D. Yoo.  International Conference on Computer Vision (ICCV) 2025 <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2508.00398-b31b1b.svg)](https://arxiv.org/abs/2508.00398)
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/dbstjswo505/OSF)
[![Star](https://img.shields.io/github/stars/dbstjswo505/OSF.svg?style=social&label=Star)](https://github.com/dbstjswo505/OSF)

[2024]
- [SimPSI: A Simple Strategy to Preserve Spectral Information in Time Series Data Augmentation](https://arxiv.org/abs/2312.05790) <br/>
Junghyun Lee, Gwangsu Kim, Matt Olfat, Mark Hasegawa-Johnson, Chang D. Yoo. in AAAI Conference on Artificial Intelligence (AAAI) 2024. <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2312.05790-b31b1b.svg)](https://arxiv.org/abs/2312.05790)
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/Hyun-Ryu/simpsi)
[![Star](https://img.shields.io/github/stars/Hyun-Ryu/simpsi.svg?style=social&label=Star)](https://github.com/Hyun-Ryu/simpsi)

[2023]
- [HEAR: Hearing Enhanced Audio Response for Video-grounded Dialogue](https://arxiv.org/abs/2312.09736) <br/>
Sunjae Yoon, Dahyun Kim, Eunseop Yoon, Hee Suk Yoon, Junyeong Kim, Chnag D. Yoo. Empirical Methods in Natural Language Processing (EMNLP) 2023. <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2312.09736-b31b1b.svg)](https://arxiv.org/abs/2312.09736)
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/dbstjswo505/HEAR)
[![Star](https://img.shields.io/github/stars/dbstjswo505/HEAR.svg?style=social&label=Star)](https://github.com/dbstjswo505/HEAR)

[2022]
- [Fast and Efficient MMD-based Fair PCA via Optimization over Stiefel Manifold](https://arxiv.org/abs/2109.11196) <br/>
Junghyun Lee, Gwangsu Kim, Matt Olfat, Mark Hasegawa-Johnson, Chang D. Yoo. in AAAI Conference on Artificial Intelligence (AAAI) 2022. <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2109.11196-b31b1b.svg)](https://arxiv.org/abs/2109.11196)
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/nick-jhlee/fair-manifold-pca)
[![Star](https://img.shields.io/github/stars/nick-jhlee/fair-manifold-pca.svg?style=social&label=Star)](https://github.com/nick-jhlee/fair-manifold-pca)

- [SoftGroup for 3D Instance Segmentation on Point Clouds](https://arxiv.org/abs/2203.01509) <br/>
Thang Vu, Kookhoi Kim, Tung Luu, Thanh Nguyen, Chang D. Yoo., Computer Vision and Pattern Recognition (CVPR) 2022, [Oral presentation (top 4%)] <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2203.01509-b31b1b.svg)](https://arxiv.org/abs/2203.01509)
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/thangvubk/SoftGroup)
[![Star](https://img.shields.io/github/stars/thangvubk/SoftGroup.svg?style=social&label=Star)](https://github.com/thangvubk/SoftGroup)


### üìù  Ïö∞Ïàò ÎÖºÎ¨∏ Ïã§Ï†Å
[2025]
- [Policy Learning from Large Vision-Language Model Feedback without Reward Modeling](https://arxiv.org/abs/2507.23391) <br/>
Tung M. Luu, Donghoon Lee, Younghwan Lee, Chang D. Yoo, The IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2025. <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2507.23391-b31b1b.svg)](https://arxiv.org/abs/2507.23391)
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)] (Comming soon!)

[2024]
- [BI-MDRG: Bridging Image History in Multimodal Dialogue Response Generation](https://arxiv.org/abs/2408.05926) <br/>
Hee Suk Yoon, Eunseop Yoon, Joshua Tian Jin Tee, Kang Zhang, Yu-Jung Heo, Du-Seong Chang, Chang D. Yoo., European Conference on Computer Vision (ECCV) 2024, <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2203.01509-b31b1b.svg)](https://arxiv.org/abs/2408.05926)
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/hee-suk-yoon/BI-MDRG)
[![Star](https://img.shields.io/github/stars/hee-suk-yoon/BI-MDRG.svg?style=social&label=Star)](https://github.com/hee-suk-yoon/BI-MDRG)

- [FlexiEdit: Frequency-Aware Latent Refinement for Enhanced Non-Rigid Editing](https://arxiv.org/abs/2407.17850) <br/>
Gwanhyeong Koo, Sunjae Yoon, Ji Woo Hong, Chang D. Yoo, European Conference on Computer Vision (ECCV) 2024. <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2203.01509-b31b1b.svg)](https://arxiv.org/abs/2407.17850)
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/kookie12/FlexiEdit)
[![Star](https://img.shields.io/github/stars/kookie12/FlexiEdit.svg?style=social&label=Star)](https://github.com/kookie12/FlexiEdit)

- [FRAG: Frequency Adapting Group for Diffusion Video Editing](https://arxiv.org/abs/2406.06044) <br/>
Sunjae Yoon, Gwanhyeong Koo, Geonwoo Kim, Chang D. Yoo, International Conference on Machine Learning (ICML) 2024. <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2203.01509-b31b1b.svg)](https://arxiv.org/abs/2406.06044)
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/dbstjswo505/FRAG)
[![Star](https://img.shields.io/github/stars/dbstjswo505/FRAG.svg?style=social&label=Star)](https://github.com/dbstjswo505/FRAG)

- [Cross-view Masked Diffusion Transformers for Person Image Synthesis](https://arxiv.org/abs/2402.01516) <br/>
Trung X. Pham, Zhang Kang, Chang D. Yoo, International Conference on Machine Learning (ICML) 2024. <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2203.01509-b31b1b.svg)](https://arxiv.org/abs/2402.01516)
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/trungpx/xmdpt)
[![Star](https://img.shields.io/github/stars/trungpx/xmdpt.svg?style=social&label=Star)](https://github.com/trungpx/xmdpt)

[2022]
- [Dual Temperature Helps Contrastive Learning Without Many Negative Samples: Towards Understanding and Simplifying MoCo](https://arxiv.org/abs/2203.17248) <br/>
Chaoning Zhang*, Kang Zhang*, Trung Pham*, Axi Niu, Zhinan Qiao, Chang D. Yoo, In So Kweon. Computer Vision and Pattern Recognition (CVPR) 2022 <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2203.17248-b31b1b.svg)](https://arxiv.org/abs/2203.17248) 
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/ChaoningZhang/Dual-temperature)
[![Star](https://img.shields.io/github/stars/ChaoningZhang/Dual-temperature.svg?style=social&label=Star)](https://github.com/ChaoningZhang/Dual-temperature)

- [Selective Query-guided Debiasing for Video Corpus Moment Retrieval](https://arxiv.org/abs/2210.08714) <br/>
Sunjae Yoon, Ji Woo Hong, Eunseop Yoon, DaHyun Kim, Junyeong Kim, Hee Suk Yoon, Chang D. Yoo., European Conference on Computer Vision (ECCV) 2022 <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2210.08714-b31b1b.svg)](https://arxiv.org/abs/2210.08714) 
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/dbstjswo505/SQuiDNet)
[![Star](https://img.shields.io/github/stars/dbstjswo505/SQuiDNet.svg?style=social&label=Star)](https://github.com/dbstjswo505/SQuiDNet)



### üèãÔ∏è‚ÄçÔ∏è SCIE Ï†ÄÎÑê Ïã§Ï†Å
[2024]
- [Causal Localization Network for Radar Human Localization With Micro-Doppler Signature](https://ieeexplore.ieee.org/document/10387441) <br/>
Sunjae Yoon, Gwanhyeong Koo, Jun Yeop Shim, Soohwan Eom, Ji Woo Hong, Chang D. Yoo., IEEE Access 2024 <br/>
[[Paper](https://ieeexplore.ieee.org/document/10387441)]
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/dbstjswo505/CLNet)
[![Star](https://img.shields.io/github/stars/dbstjswo505/CLNet.svg?style=social&label=Star)](https://github.com/dbstjswo505/CLNet)

[2022]
- [Dual-scale Doppler Attention for Human Identification](https://www.mdpi.com/1424-8220/22/17/6363) <br/>
Sunjae Yoon, Dahyun Kim, Ji Woo Hong, Junyeong Kim, Chang D. Yoo, Sensors 2022 <br/>
[[Paper](https://www.mdpi.com/1424-8220/22/17/6363)]
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/dbstjswo505/DSDA)
[![Star](https://img.shields.io/github/stars/dbstjswo505/DSDA.svg?style=social&label=Star)](https://github.com/dbstjswo505/DSDA)

- [LAD: A Hybrid Deep Learning System for Benign Paroxysmal Positional Vertigo Disorders Diagnostic](https://arxiv.org/abs/2210.08282) <br/>
Trung Xuan Pham, Jin Woong Choi, Rusty John Lloyd Mina, Thanh Nguyen, Sultan Rizky Madjid, and Chang D. Yoo, IEEE Access 2022 <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2210.08282-b31b1b.svg)](https://arxiv.org/abs/2210.08282)
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/trungpx/lad)
[![Star](https://img.shields.io/github/stars/trungpx/lad.svg?style=social&label=Star)](https://github.com/trungpx/lad)



### ‚ÄçÔ∏èüè∑Ô∏è Íµ≠Ï†ú ÌïôÏà† ÎåÄÌöå Ïã§Ï†Å
[2024]
- [Progressive Fourier Neural Representation for Sequential Video Compilation](https://arxiv.org/abs/2306.11305) <br/>
Haeyong Kang, Jaehong Yoon, DaHyun Kim, Sung Ju Hwang, Chang D Yoo, International Conference on Learning Representations (ICLR) 2024, <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2306.11305-b31b1b.svg)](https://arxiv.org/abs/2306.11305)
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/ihaeyong/PFNR)
[![Star](https://img.shields.io/github/stars/ihaeyong/PFNR.svg?style=social&label=Star)](https://github.com/ihaeyong/PFNR)

- [Querying Easily Flip-flopped Samples for Deep Active Learning](https://arxiv.org/abs/2401.09787) <br/>
Seong Jin Cho, Gwangsu Kim, Junghyun Lee, Jinwoo Shin, Chang D. Yoo, International Conference on Learning Representations (ICLR) 2024, <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2401.09787-b31b1b.svg)](https://arxiv.org/abs/2401.09787)
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/ipcng00/LDM-S)
[![Star](https://img.shields.io/github/stars/ipcng00/LDM-S.svg?style=social&label=Star)](https://github.com/ipcng00/LDM-S)

- [Physics Informed Distillation for Diffusion Models](https://arxiv.org/abs/2411.08378) <br/>
Joshua Tian Jin Tee, Kang Zhang, Hee Suk Yoon, Dhananjaya Nagaraja Gowda, Chanwoo Kim, Chang D. Yoo, Transactions on Machine Learning Research (TMLR) 2024, <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2411.08378-b31b1b.svg)](https://arxiv.org/abs/2401.09787)
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/pantheon5100/pid_diffusion)
[![Star](https://img.shields.io/github/stars/pantheon5100/pid_diffusion.svg?style=social&label=Star)](https://github.com/pantheon5100/pid_diffusion)

[2023]
- [On the Soft-Subnetwork for Few-Shot Class Incremental Learning](https://arxiv.org/abs/2209.07529) <br/>
Seong Jin Cho, Gwangsu Kim, Junghyun Lee, Jinwoo Shin, Chang D. Yoo, International Conference on Learning Representations (ICLR) 2023, <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2209.07529-b31b1b.svg)](https://arxiv.org/abs/2209.07529)
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/ihaeyong/SoftNet-FSCIL)
[![Star](https://img.shields.io/github/stars/ihaeyong/SoftNet-FSCIL.svg?style=social&label=Star)](https://github.com/ihaeyong/SoftNet-FSCIL)

- [ESD: Expected Squared Difference as a Tuning-Free Trainable Calibration Measure](https://arxiv.org/abs/2303.02472) <br/>
Hee Suk Yoon, Joshua Tian Jin Tee, Eunseop Yoon, Sunjae Yoon, Gwangsu Kim, Yingzhen Li, Chang D. Yoo, International Conference on Learning Representations (ICLR) 2023, <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2303.02472-b31b1b.svg)](https://arxiv.org/abs/2303.02472)
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/hee-suk-yoon/ESD)
[![Star](https://img.shields.io/github/stars/hee-suk-yoon/ESD.svg?style=social&label=Star)](https://github.com/hee-suk-yoon/ESD)

- [Scene Complexity Aware Network for Weakly-Supervised Video Moment RetrievaL](https://arxiv.org/abs/2310.05241) <br/>
Sunjae Yoon, Gwanhyeong Koo, Dahyun Kim, Chang D. Yoo.  International Conference on Computer Vision (ICCV) 2023 <br/>
[![arXiv](https://img.shields.io/badge/arXiv-2310.05241-b31b1b.svg)](https://arxiv.org/abs/2310.05241)
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/dbstjswo505/SCANet)
[![Star](https://img.shields.io/github/stars/dbstjswo505/SCANet.svg?style=social&label=Star)](https://github.com/dbstjswo505/SCANet)


### ‚ÄçÔ∏è‚öôÔ∏è Í∏∞ÌÉÄ ÏÜåÌîÑÌä∏Ïõ®Ïñ¥
[2023]
- [ÎπÑÎîîÏò§ Í∏∞Î∞ò Ïù∏Í≥µÏßÄÎä• ÎåÄÌôî ÏãúÏä§ÌÖú(StarLab-Dialogue-System)] <br/>
[![github](https://img.shields.io/badge/GitHub-gray?style=flat&logo=GitHub&logoColor=black)](https://github.com/U-AIM-SW-STARLab/StarLab-Dialogue-System)
[![Star](https://img.shields.io/github/stars/U-AIM-SW-STARLab/StarLab-Dialogue-System.svg?style=social&label=Star)](https://github.com/U-AIM-SW-STARLab/StarLab-Dialogue-System)
